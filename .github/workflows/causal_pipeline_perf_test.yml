name: 'Causal Pipeline Performance Test'

on:
  workflow_dispatch:
  pull_request:

permissions:
  contents: read
  pull-requests: read

jobs:
  tests:
    runs-on: ubuntu-latest
    steps:
      # â”€â”€â”€ Setup â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'

      - name: Clean outputs & create venv
        run: |
          rm -rf ./outputs/causal
          python -m venv .venv
          echo "${{ github.workspace }}/.venv/bin" >> $GITHUB_PATH

      - name: Install dependencies
        run: pip install --no-cache-dir -r requirements.txt
      - name: Set Python path
        run: |
          echo "PYTHONPATH=$PYTHONPATH:$(pwd)" >> $GITHUB_ENV

      # â”€â”€â”€ Pipeline & Tests â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
      - name: Run finetune performance test
        shell: bash
        run: |
          set -euo pipefail
          run_step() {
            module="$1"; config="$2"
            echo
            echo "ðŸ”§ Running corebehrt.$module ($config)"
            python -m corebehrt.$module \
              --config_path corebehrt/configs/causal/$config
          }

          # â”€â”€â”€ Data prep & pretrain â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
          run_step main.create_data prepare_and_pretrain/create_data.yaml
          run_step main.prepare_training_data prepare_and_pretrain/prepare_pretrain.yaml
          run_step main.pretrain prepare_and_pretrain/pretrain.yaml
          run_step main.create_outcomes outcomes.yaml
          run_step main_causal.select_cohort_full select_cohort_full/extract.yaml
          # â”€â”€â”€ Prepare Finetune Data â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
          run_step main.prepare_training_data finetune/prepare/ft_exp_uncensored.yaml
          echo "ðŸ”§ Checking Uncensored Data."
          echo "We expect that all the triggers are the same as the outcomes."
          python -m tests.pipeline.test_uncensored_prepared --processed_data_dir ./outputs/causal/finetune/processed_data/exposure_uncensored --trigger_code EXPOSURE
          echo "ðŸ”§ Training XGBoost Baseline on uncensored data and checking performance"
          python -m tests.pipeline.train_xgb_baseline --data_path ./outputs/causal/finetune/processed_data/exposure_uncensored --min_roc_auc 0.95 --expected_most_important_concept EXPOSURE

          run_step main.prepare_training_data finetune/prepare/ft_exp.yaml
          echo "ðŸ”§ Training XGBoost Baseline on censored data and checking performance"
          python -m tests.pipeline.train_xgb_baseline --data_path ./outputs/causal/finetune/processed_data/exposure --min_roc_auc 0.6 --multihot

          # â”€â”€â”€ Finetune Exposure & Outcome â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
          run_step main.finetune_cv finetune/ft_exp_uncensored.yaml
          echo "ðŸ”§ Checking Performance uncensored"
          python -m tests.pipeline.test_performance ./outputs/causal/finetune/models/exposure_uncensored --min 0.8

          run_step main.finetune_cv finetune/ft_exp.yaml
          echo "ðŸ”§ Checking Performance"
          python -m tests.pipeline.test_performance ./outputs/causal/finetune/models/exposure --min 0.6 --max 0.8
          
          
          
         
          
