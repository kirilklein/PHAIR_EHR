logging:
  level: INFO
  path: ./outputs/logs/causal

paths:
  ## INPUTS
  pretrain_model: ./outputs/causal/pretrain/model
  prepared_data: ./outputs/causal/finetune/processed_data/exposure_uncensored

  ## OUTPUTS
  model: ./outputs/causal/finetune/models/exposure_uncensored # Save model/outputs to this folder

model:
  head:
    shared_representation: true # whether to share the bigru representation for exposure and outcome
    bidirectional: true

trainer_args:
  sampler_function:
    _target_: corebehrt.modules.trainer.utils.Sampling.effective_n_samples # function to calculate sample weights. Possible options: inverse_sqrt and effective_n_samples
  loss_weight_function:
    _target_: corebehrt.modules.trainer.utils.PositiveWeight.effective_n_samples # function to calculate positive weights. Possible options: sqrt and effective_n_samples
  batch_size: 128
  val_batch_size: 256
  effective_batch_size: 128
  epochs: 6
  info: true
  gradient_clip:
    clip_value: 1.0
  shuffle: true
  checkpoint_frequency: 1
  early_stopping: 2
  stopping_criterion: roc_auc

  # Freezing options
  n_layers_to_freeze: 1
  unfreeze_on_plateau: false # unfreeze all layers if the performance is less than plateau_threshold
  unfreeze_at_epoch: 10 # if unfrezze_on_plateau is true, whichever condition is met first
  plateau_threshold: 0.01
  reset_patience_after_unfreeze: true # reset early stopping counter after unfreezing

optimizer:
  lr: 1e-2
  eps: 1e-6

scheduler:
  _target_: transformers.get_linear_schedule_with_warmup
  num_warmup_epochs: 3
  num_training_epochs: 20

metrics:
  accuracy:
    _target_: corebehrt.modules.monitoring.metrics.Accuracy
    threshold: 0.6
  roc_auc:
    _target_: corebehrt.modules.monitoring.metrics.ROC_AUC

  pr_auc:
    _target_: corebehrt.modules.monitoring.metrics.PR_AUC

  mean_probability:
    _target_: corebehrt.modules.monitoring.metrics.Mean_Probability
