logging:
  # Logging verbosity level (e.g., DEBUG, INFO, WARNING, ERROR)
  level: INFO
  # Optional: path to a log file. If omitted, logs to console.
  path: ./outputs/logs/causal/baseline.log

paths:
  # --- INPUTS ---
  # Path to the directory containing the prepared patient data and vocabulary.
  prepared_data: ./outputs/causal/finetune/prepared_data_simulated

  # --- OUTPUTS ---
  # Main directory where all outputs for this baseline run will be saved.
  # This includes models, results, and fold definitions.
  model: ./outputs/causal/finetune/models/baseline/simulated

# ==============================================================================
# Feature Engineering Settings
# ==============================================================================
# These settings control how patient data is converted into a feature matrix.
multihot: false # If true, use feature counts (multi-hot). If false, use binary presence (one-hot).
include_age: true # If true, include age-based features (mean, min, max, std, range).

# ==============================================================================
# Model Parameters (CatBoost)
# ==============================================================================
# These are the base parameters for the CatBoost model.
# They are used directly if tuning is disabled, or as a starting point for tuning.
catboost:
  n_estimators: 100 # Max number of trees. Training will likely stop early.
  learning_rate: 0.03 # Step size shrinkage to prevent overfitting.
  max_depth: 6 # Maximum depth of each tree.
  subsample: 0.8 # Fraction of objects to sample for each tree (row sampling).
  colsample_bylevel: 0.8 # Fraction of features to sample for each level (column sampling).
  l2_leaf_reg: 0 # L2 regularization term on weights.
  early_stopping_rounds: 10 # Stop training if the validation score doesn't improve for this many rounds.

# ==============================================================================
# Hyperparameter Tuning Settings (Optuna)
# ==============================================================================
# Settings for the inner loop of the nested cross-validation.
tuning:
  # Master switch to enable or disable hyperparameter tuning.
  # If false, the base `catboost` parameters above will be used for all folds.
  tune_hyperparameters: True

  # Number of different hyperparameter combinations to try in the Optuna search.
  n_trials: 10

  # [NEW] The proportion of the outer training set to use for validation in the inner loop.
  # For example, 0.2 means an 80/20 split for inner training/validation.
  inner_val_size: 0.2

  # [NEW] If true, tune hyperparameters only on the first fold and reuse them for
  # all subsequent folds. This provides a significant speed-up at the cost of
  # slightly less robust hyperparameter selection. Recommended for faster experiments.
  reuse_hyperparameters: true
# ==============================================================================
# Target and Evaluation Settings
# ==============================================================================

# Optional: Specify which targets to train models for.
# If this section is commented out, the script will automatically train a model
# for the exposure and all outcomes found in the dataset.
# targets: ["exposure", "OUTCOME", "OUTCOME_2"]
